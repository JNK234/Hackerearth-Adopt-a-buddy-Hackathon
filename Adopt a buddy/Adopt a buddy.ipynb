{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18834it [00:00, 49922.60it/s]\n",
      "8072it [00:00, 47714.47it/s]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "\n",
    "def cleanDate(issue_date,listing_date):\n",
    "    \n",
    "    format = '%Y-%m-%d %H:%M:%S'\n",
    "    issue_date = datetime.strptime(issue_date,format)\n",
    "    listing_date = datetime.strptime(listing_date,format)\n",
    "    \n",
    "    date = str(listing_date - issue_date).replace('days','')\n",
    "    date = date.replace(' ','')\n",
    "    date = date.split(',')\n",
    "    time = date[1].split(\":\")\n",
    "    hrs = float(date[0])*24 + float(time[0]) + float(time[1])/24 + float(time[2])/(24*60)\n",
    "    \n",
    "    return hrs\n",
    "\n",
    "\n",
    "train_data = pd.read_csv('Dataset-2/train.csv')\n",
    "test_data = pd.read_csv('Dataset-2/test.csv')\n",
    "\n",
    "test_data['condition'].fillna(0,inplace = True)\n",
    "train_data['condition'].fillna(0,inplace = True)\n",
    "\n",
    "ids = test_data['pet_id']\n",
    "s = pd.get_dummies(train_data['color_type'])\n",
    "p = pd.get_dummies(test_data['color_type'])\n",
    "X = pd.concat([train_data,s],axis=1)\n",
    "y = pd.concat([test_data,p],axis = 1)\n",
    "\n",
    "X = X.drop('color_type',axis=1)\n",
    "y = y.drop('color_type',axis=1)\n",
    "\n",
    "X_train = X.drop(['breed_category','pet_category','pet_id'],axis = 1)\n",
    "\n",
    "date_diff = []\n",
    "listing_date = list(X_train['listing_date'])\n",
    "issue_date = list(X_train['issue_date'])\n",
    "\n",
    "for i,j in tqdm(zip(issue_date,listing_date)):\n",
    "    diff = cleanDate(i,j)\n",
    "    date_diff.append(diff)\n",
    "\n",
    "X_train['date_diff (hrs)'] = pd.Series(date_diff)\n",
    "X_train = X_train.drop('issue_date',axis=1)\n",
    "X_train = X_train.drop('listing_date',axis=1)\n",
    "\n",
    "date_diff1 = []\n",
    "listing_date1 = list(y['listing_date'])\n",
    "issue_date1 = list(y['issue_date'])\n",
    "\n",
    "for i,j in tqdm(zip(issue_date1,listing_date1)):\n",
    "    diff = cleanDate(i,j)\n",
    "    date_diff1.append(diff)\n",
    "\n",
    "y['date_diff (hrs)'] = pd.Series(date_diff1)\n",
    "y = y.drop('issue_date',axis=1)\n",
    "y = y.drop('listing_date',axis=1)\n",
    "y = y.drop('pet_id',axis=1)\n",
    "\n",
    "y['date_diff (hrs)'] = y['date_diff (hrs)'].round(2)\n",
    "X_train['date_diff (hrs)'] = X_train['date_diff (hrs)'].round(2)\n",
    "\n",
    "X_test = X[['breed_category','pet_category']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "y['Black Tiger'] = 0\n",
    "y['Brown Tiger'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>condition</th>\n",
       "      <th>length(m)</th>\n",
       "      <th>height(cm)</th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>Agouti</th>\n",
       "      <th>Apricot</th>\n",
       "      <th>Black</th>\n",
       "      <th>Black Brindle</th>\n",
       "      <th>Black Smoke</th>\n",
       "      <th>...</th>\n",
       "      <th>Torbie</th>\n",
       "      <th>Tortie</th>\n",
       "      <th>Tortie Point</th>\n",
       "      <th>Tricolor</th>\n",
       "      <th>White</th>\n",
       "      <th>Yellow</th>\n",
       "      <th>Yellow Brindle</th>\n",
       "      <th>date_diff (hrs)</th>\n",
       "      <th>Black Tiger</th>\n",
       "      <th>Brown Tiger</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.87</td>\n",
       "      <td>42.73</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>105712.46</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.06</td>\n",
       "      <td>6.71</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4194.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.24</td>\n",
       "      <td>41.21</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>47994.12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.29</td>\n",
       "      <td>8.46</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27560.04</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.71</td>\n",
       "      <td>30.92</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11126.75</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8067</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.82</td>\n",
       "      <td>36.08</td>\n",
       "      <td>13</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9472.33</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8068</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.49</td>\n",
       "      <td>27.54</td>\n",
       "      <td>13</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19152.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8069</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.98</td>\n",
       "      <td>37.19</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9449.79</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8070</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.79</td>\n",
       "      <td>23.83</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9306.79</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8071</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.64</td>\n",
       "      <td>24.51</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9425.96</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8072 rows Ã— 62 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      condition  length(m)  height(cm)  X1  X2  Agouti  Apricot  Black  \\\n",
       "0           0.0       0.87       42.73   0   7       0        0      1   \n",
       "1           1.0       0.06        6.71   0   1       0        0      0   \n",
       "2           1.0       0.24       41.21   0   7       0        0      1   \n",
       "3           1.0       0.29        8.46   7   1       0        0      1   \n",
       "4           1.0       0.71       30.92   0   7       0        0      0   \n",
       "...         ...        ...         ...  ..  ..     ...      ...    ...   \n",
       "8067        2.0       0.82       36.08  13   9       0        0      0   \n",
       "8068        0.0       0.49       27.54  13   9       0        0      0   \n",
       "8069        0.0       0.98       37.19   0   7       0        0      1   \n",
       "8070        0.0       0.79       23.83   0   2       0        0      1   \n",
       "8071        0.0       0.64       24.51   0   1       0        0      1   \n",
       "\n",
       "      Black Brindle  Black Smoke  ...  Torbie  Tortie  Tortie Point  Tricolor  \\\n",
       "0                 0            0  ...       0       0             0         0   \n",
       "1                 0            0  ...       0       0             0         0   \n",
       "2                 0            0  ...       0       0             0         0   \n",
       "3                 0            0  ...       0       0             0         0   \n",
       "4                 0            0  ...       0       0             0         0   \n",
       "...             ...          ...  ...     ...     ...           ...       ...   \n",
       "8067              0            0  ...       0       0             0         0   \n",
       "8068              0            0  ...       0       0             0         0   \n",
       "8069              0            0  ...       0       0             0         0   \n",
       "8070              0            0  ...       0       0             0         0   \n",
       "8071              0            0  ...       0       0             0         0   \n",
       "\n",
       "      White  Yellow  Yellow Brindle  date_diff (hrs)  Black Tiger  Brown Tiger  \n",
       "0         0       0               0        105712.46            0            0  \n",
       "1         0       0               0          4194.00            0            0  \n",
       "2         0       0               0         47994.12            0            0  \n",
       "3         0       0               0         27560.04            0            0  \n",
       "4         0       0               0         11126.75            0            0  \n",
       "...     ...     ...             ...              ...          ...          ...  \n",
       "8067      0       0               0          9472.33            0            0  \n",
       "8068      0       0               0         19152.00            0            0  \n",
       "8069      0       0               0          9449.79            0            0  \n",
       "8070      0       0               0          9306.79            0            0  \n",
       "8071      0       0               0          9425.96            0            0  \n",
       "\n",
       "[8072 rows x 62 columns]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set()\n"
     ]
    }
   ],
   "source": [
    "l1 = set(['condition', 'length(m)', 'height(cm)', 'X1', 'X2', 'Agouti', 'Apricot', 'Black', 'Black Brindle', 'Black Smoke', 'Black Tabby', 'Black Tiger', 'Blue', 'Blue Cream', 'Blue Merle', 'Blue Point', 'Blue Smoke', 'Blue Tabby', 'Blue Tick', 'Blue Tiger', 'Brown', 'Brown Brindle', 'Brown Merle', 'Brown Tabby', 'Brown Tiger', 'Buff', 'Calico', 'Calico Point', 'Chocolate', 'Chocolate Point', 'Cream', 'Cream Tabby', 'Fawn', 'Flame Point', 'Gold', 'Gray', 'Gray Tabby', 'Green', 'Lilac Point', 'Liver', 'Liver Tick', 'Lynx Point', 'Orange', 'Orange Tabby', 'Pink', 'Red', 'Red Merle', 'Red Tick', 'Sable', 'Seal Point', 'Silver', 'Silver Lynx Point', 'Silver Tabby', 'Tan', 'Torbie', 'Tortie', 'Tortie Point', 'Tricolor', 'White', 'Yellow', 'Yellow Brindle', 'date_diff (hrs)'])\n",
    "l2 = set(['condition', 'length(m)', 'height(cm)', 'X1', 'X2', 'Agouti', 'Apricot', 'Black', 'Black Brindle', 'Black Smoke', 'Black Tabby', 'Blue', 'Blue Cream', 'Blue Merle', 'Blue Point', 'Blue Smoke', 'Blue Tabby', 'Blue Tick', 'Blue Tiger', 'Brown', 'Brown Brindle', 'Brown Merle', 'Brown Tabby', 'Buff', 'Calico', 'Calico Point', 'Chocolate', 'Chocolate Point', 'Cream', 'Cream Tabby', 'Fawn', 'Flame Point', 'Gold', 'Gray', 'Gray Tabby', 'Green', 'Lilac Point', 'Liver', 'Liver Tick', 'Lynx Point', 'Orange', 'Orange Tabby', 'Pink', 'Red', 'Red Merle', 'Red Tick', 'Sable', 'Seal Point', 'Silver', 'Silver Lynx Point', 'Silver Tabby', 'Tan', 'Torbie', 'Tortie', 'Tortie Point', 'Tricolor', 'White', 'Yellow', 'Yellow Brindle', 'date_diff (hrs)', 'Black Tiger', 'Brown Tiger'])\n",
    "print(l1 - l2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        2.0\n",
      "1        1.0\n",
      "2        0.0\n",
      "3        1.0\n",
      "4        2.0\n",
      "        ... \n",
      "18829    2.0\n",
      "18830    0.0\n",
      "18831    0.0\n",
      "18832    0.0\n",
      "18833    0.0\n",
      "Name: condition, Length: 18834, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(X_train.iloc[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['condition', 'length(m)', 'height(cm)', 'X1', 'X2', 'Agouti', 'Apricot',\n",
      "       'Black', 'Black Brindle', 'Black Smoke', 'Black Tabby', 'Black Tiger',\n",
      "       'Blue', 'Blue Cream', 'Blue Merle', 'Blue Point', 'Blue Smoke',\n",
      "       'Blue Tabby', 'Blue Tick', 'Blue Tiger', 'Brown', 'Brown Brindle',\n",
      "       'Brown Merle', 'Brown Tabby', 'Brown Tiger', 'Buff', 'Calico',\n",
      "       'Calico Point', 'Chocolate', 'Chocolate Point', 'Cream', 'Cream Tabby',\n",
      "       'Fawn', 'Flame Point', 'Gold', 'Gray', 'Gray Tabby', 'Green',\n",
      "       'Lilac Point', 'Liver', 'Liver Tick', 'Lynx Point', 'Orange',\n",
      "       'Orange Tabby', 'Pink', 'Red', 'Red Merle', 'Red Tick', 'Sable',\n",
      "       'Seal Point', 'Silver', 'Silver Lynx Point', 'Silver Tabby', 'Tan',\n",
      "       'Torbie', 'Tortie', 'Tortie Point', 'Tricolor', 'White', 'Yellow',\n",
      "       'Yellow Brindle', 'date_diff (hrs)'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(X_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['condition', 'length(m)', 'height(cm)', 'X1', 'X2', 'Agouti', 'Apricot',\n",
      "       'Black', 'Black Brindle', 'Black Smoke', 'Black Tabby', 'Blue',\n",
      "       'Blue Cream', 'Blue Merle', 'Blue Point', 'Blue Smoke', 'Blue Tabby',\n",
      "       'Blue Tick', 'Blue Tiger', 'Brown', 'Brown Brindle', 'Brown Merle',\n",
      "       'Brown Tabby', 'Buff', 'Calico', 'Calico Point', 'Chocolate',\n",
      "       'Chocolate Point', 'Cream', 'Cream Tabby', 'Fawn', 'Flame Point',\n",
      "       'Gold', 'Gray', 'Gray Tabby', 'Green', 'Lilac Point', 'Liver',\n",
      "       'Liver Tick', 'Lynx Point', 'Orange', 'Orange Tabby', 'Pink', 'Red',\n",
      "       'Red Merle', 'Red Tick', 'Sable', 'Seal Point', 'Silver',\n",
      "       'Silver Lynx Point', 'Silver Tabby', 'Tan', 'Torbie', 'Tortie',\n",
      "       'Tortie Point', 'Tricolor', 'White', 'Yellow', 'Yellow Brindle',\n",
      "       'date_diff (hrs)', 'Black Tiger', 'Brown Tiger'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(y.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y[X_train.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['condition', 'length(m)', 'height(cm)', 'X1', 'X2', 'Agouti', 'Apricot',\n",
       "       'Black', 'Black Brindle', 'Black Smoke', 'Black Tabby', 'Black Tiger',\n",
       "       'Blue', 'Blue Cream', 'Blue Merle', 'Blue Point', 'Blue Smoke',\n",
       "       'Blue Tabby', 'Blue Tick', 'Blue Tiger', 'Brown', 'Brown Brindle',\n",
       "       'Brown Merle', 'Brown Tabby', 'Brown Tiger', 'Buff', 'Calico',\n",
       "       'Calico Point', 'Chocolate', 'Chocolate Point', 'Cream', 'Cream Tabby',\n",
       "       'Fawn', 'Flame Point', 'Gold', 'Gray', 'Gray Tabby', 'Green',\n",
       "       'Lilac Point', 'Liver', 'Liver Tick', 'Lynx Point', 'Orange',\n",
       "       'Orange Tabby', 'Pink', 'Red', 'Red Merle', 'Red Tick', 'Sable',\n",
       "       'Seal Point', 'Silver', 'Silver Lynx Point', 'Silver Tabby', 'Tan',\n",
       "       'Torbie', 'Tortie', 'Tortie Point', 'Tricolor', 'White', 'Yellow',\n",
       "       'Yellow Brindle', 'date_diff (hrs)'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:07,  7.52s/it]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import svm, tree\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "\n",
    "\n",
    "# classifiers = []\n",
    "\n",
    "# model2 = tree.DecisionTreeClassifier()\n",
    "# classifiers.append(model2)\n",
    "\n",
    "# model3 = RandomForestClassifier()\n",
    "# classifiers.append(model3)\n",
    "\n",
    "classifiers_breed = []\n",
    "classifiers_pet = []\n",
    "\n",
    "# model2_breed = svm.SVC()\n",
    "# model2_pet = svm.SVC()\n",
    "# classifiers_breed.append(model2_breed)\n",
    "# classifiers_pet.append(model2_pet)\n",
    "\n",
    "# model1_breed = LogisticRegression()\n",
    "# model1_pet = LogisticRegression()\n",
    "# classifiers_breed.append(model1_breed)\n",
    "# classifiers_pet.append(model1_pet)\n",
    "\n",
    "# gnb1 = GaussianNB()\n",
    "# gnb2 = GaussianNB()\n",
    "# classifiers_breed.append(gnb1)\n",
    "# classifiers_pet.append(gnb2)\n",
    "\n",
    "# model1 = XGBClassifier()\n",
    "# model2 = XGBClassifier()\n",
    "# classifiers_breed.append(model1)\n",
    "# classifiers_pet.append(model2)\n",
    "\n",
    "clf1 = MLPClassifier()\n",
    "clf2 = MLPClassifier()\n",
    "classifiers_breed.append(clf1)\n",
    "classifiers_pet.append(clf2)\n",
    "\n",
    "# for clf in classifiers:\n",
    "#     clf.fit(X_train,X_test)\n",
    "    \n",
    "#     predictions = clf.predict(y)\n",
    "    \n",
    "#     file = open('SET1/submission'+ str(clf) +'_updated.csv','a')\n",
    "#     file.write('pet_id,breed_category,pet_category')\n",
    "#     file.write('\\n')\n",
    "#     preds_breed_sgd = list(predictions[:,0])\n",
    "#     preds_pet_sgd = list(predictions[:,1])\n",
    "#     for id,breed,pet in zip(ids,preds_breed_sgd,preds_pet_sgd):\n",
    "#         file.write(str(id)+\",\"+str(int(breed))+\",\"+str(int(pet)))\n",
    "#         file.write('\\n')\n",
    "    \n",
    "#     file.close()\n",
    "    \n",
    "for clf_breed,clf_pet in tqdm(zip(classifiers_breed,classifiers_pet)):\n",
    "    clf_breed.fit(X_train,X_test.iloc[:,0])\n",
    "    clf_pet.fit(X_train,X_test.iloc[:,1])\n",
    "    \n",
    "    y_pred_breed = clf_breed.predict(y)\n",
    "    y_pred_pet = clf_pet.predict(y)\n",
    "    \n",
    "    file = open('SET1/submission'+ str(clf_breed)[:10] +'_updated.csv','a')\n",
    "    file.write('pet_id,breed_category,pet_category')\n",
    "    file.write('\\n')\n",
    "    for id,breed,pet in zip(ids,y_pred_breed,y_pred_pet):\n",
    "        file.write(str(id)+\",\"+str(int(breed))+\",\"+str(int(pet)))\n",
    "        file.write('\\n')\n",
    "    \n",
    "\n",
    "    file.close() \n",
    "\n",
    "# for i in range(10,110,10):\n",
    "#     model = RandomForestClassifier(n_estimators=i) \n",
    "    \n",
    "#     model.fit(X_train,X_test)\n",
    "    \n",
    "#     predictions = model.predict(y)\n",
    "    \n",
    "#     file = open('SET1/submission'+ str(model) +str(i)+'_updated.csv','a')\n",
    "#     file.write('pet_id,breed_category,pet_category')\n",
    "#     file.write('\\n')\n",
    "#     preds_breed_sgd = list(predictions[:,0])\n",
    "#     preds_pet_sgd = list(predictions[:,1])\n",
    "#     for id,breed,pet in zip(ids,preds_breed_sgd,preds_pet_sgd):\n",
    "#         file.write(str(id)+\",\"+str(int(breed))+\",\"+str(int(pet)))\n",
    "#         file.write('\\n')\n",
    "    \n",
    "#     file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trainig Set 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18834it [00:00, 40119.64it/s]\n",
      "8072it [00:00, 36328.78it/s]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "\n",
    "def cleanDate(issue_date,listing_date):\n",
    "    \n",
    "    format = '%Y-%m-%d %H:%M:%S'\n",
    "    issue_date = datetime.strptime(issue_date,format)\n",
    "    listing_date = datetime.strptime(listing_date,format)\n",
    "    \n",
    "    date = str(listing_date - issue_date).replace('days','')\n",
    "    date = date.replace(' ','')\n",
    "    date = date.split(',')\n",
    "    time = date[1].split(\":\")\n",
    "    hrs = float(date[0])*24 + float(time[0]) + float(time[1])/24 + float(time[2])/(24*60)\n",
    "    \n",
    "    return hrs\n",
    "\n",
    "\n",
    "train_data = pd.read_csv('Dataset-2/train.csv')\n",
    "test_data = pd.read_csv('Dataset-2/test.csv')\n",
    "\n",
    "test_data['condition'].fillna(1,inplace = True)\n",
    "train_data['condition'].fillna(1,inplace = True)\n",
    "\n",
    "ids = test_data['pet_id']\n",
    "s = pd.get_dummies(train_data['color_type'])\n",
    "p = pd.get_dummies(test_data['color_type'])\n",
    "X = pd.concat([train_data,s],axis=1)\n",
    "y = pd.concat([test_data,p],axis = 1)\n",
    "\n",
    "X = X.drop('color_type',axis=1)\n",
    "y = y.drop('color_type',axis=1)\n",
    "\n",
    "X_train = X.drop(['breed_category','pet_category','pet_id'],axis = 1)\n",
    "\n",
    "date_diff = []\n",
    "listing_date = list(X_train['listing_date'])\n",
    "issue_date = list(X_train['issue_date'])\n",
    "\n",
    "for i,j in tqdm(zip(issue_date,listing_date)):\n",
    "    diff = cleanDate(i,j)\n",
    "    date_diff.append(diff)\n",
    "\n",
    "X_train['date_diff (hrs)'] = pd.Series(date_diff)\n",
    "X_train = X_train.drop('issue_date',axis=1)\n",
    "X_train = X_train.drop('listing_date',axis=1)\n",
    "\n",
    "date_diff1 = []\n",
    "listing_date1 = list(y['listing_date'])\n",
    "issue_date1 = list(y['issue_date'])\n",
    "\n",
    "for i,j in tqdm(zip(issue_date1,listing_date1)):\n",
    "    diff = cleanDate(i,j)\n",
    "    date_diff1.append(diff)\n",
    "\n",
    "y['date_diff (hrs)'] = pd.Series(date_diff1)\n",
    "y = y.drop('issue_date',axis=1)\n",
    "y = y.drop('listing_date',axis=1)\n",
    "y = y.drop('pet_id',axis=1)\n",
    "\n",
    "y['date_diff (hrs)'] = y['date_diff (hrs)'].round(2)\n",
    "X_train['date_diff (hrs)'] = X_train['date_diff (hrs)'].round(2)\n",
    "\n",
    "X_test = X[['breed_category','pet_category']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "y['Black Tiger'] =0\n",
    "y['Brown Tiger'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y[X_train.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:05,  5.16s/it]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import svm, tree\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "\n",
    "\n",
    "# classifiers = []\n",
    "\n",
    "# model2 = tree.DecisionTreeClassifier()\n",
    "# classifiers.append(model2)\n",
    "\n",
    "# model3 = RandomForestClassifier()\n",
    "# classifiers.append(model3)\n",
    "\n",
    "classifiers_breed = []\n",
    "classifiers_pet = []\n",
    "# gnb11 =[]\n",
    "# gnb22 =[]\n",
    "\n",
    "# model2_breed = svm.SVC()\n",
    "# model2_pet = svm.SVC()\n",
    "# classifiers_breed.append(model2_breed)\n",
    "# classifiers_pet.append(model2_pet)\n",
    "\n",
    "# model1_breed = LogisticRegression()\n",
    "# model1_pet = LogisticRegression()\n",
    "# classifiers_breed.append(model1_breed)\n",
    "# classifiers_pet.append(model1_pet)\n",
    "\n",
    "# gnb1 = GaussianNB()\n",
    "# gnb2 = GaussianNB()\n",
    "# classifiers_breed.append(gnb1)\n",
    "# classifiers_pet.append(gnb2)\n",
    "\n",
    "# model1 = XGBClassifier()\n",
    "# model2 = XGBClassifier()\n",
    "# classifiers_breed.append(model1)\n",
    "# classifiers_pet.append(model2)\n",
    "\n",
    "\n",
    "clf1 = MLPClassifier()\n",
    "clf2 = MLPClassifier()\n",
    "classifiers_breed.append(clf1)\n",
    "classifiers_pet.append(clf2)\n",
    "\n",
    "# for clf in classifiers:\n",
    "#     clf.fit(X_train,X_test)\n",
    "    \n",
    "#     predictions = clf.predict(y)\n",
    "    \n",
    "#     file = open('SET2/submission'+ str(clf) +'_updated.csv','a')\n",
    "#     file.write('pet_id,breed_category,pet_category')\n",
    "#     file.write('\\n')\n",
    "#     preds_breed_sgd = list(predictions[:,0])\n",
    "#     preds_pet_sgd = list(predictions[:,1])\n",
    "#     for id,breed,pet in zip(ids,preds_breed_sgd,preds_pet_sgd):\n",
    "#         file.write(str(id)+\",\"+str(int(breed))+\",\"+str(int(pet)))\n",
    "#         file.write('\\n')\n",
    "    \n",
    "#     file.close()\n",
    "    \n",
    "for clf_breed,clf_pet in tqdm(zip(classifiers_breed,classifiers_pet)):\n",
    "    clf_breed.fit(X_train,X_test.iloc[:,0])\n",
    "    clf_pet.fit(X_train,X_test.iloc[:,1])\n",
    "    \n",
    "    y_pred_breed = clf_breed.predict(y)\n",
    "    y_pred_pet = clf_pet.predict(y)\n",
    "    \n",
    "    file = open('SET2/submission'+ str(clf_breed)[:10] +'_updated.csv','a')\n",
    "    file.write('pet_id,breed_category,pet_category')\n",
    "    file.write('\\n')\n",
    "    for id,breed,pet in zip(ids,y_pred_breed,y_pred_pet):\n",
    "        file.write(str(id)+\",\"+str(int(breed))+\",\"+str(int(pet)))\n",
    "        file.write('\\n')\n",
    "    \n",
    "\n",
    "    file.close() \n",
    "\n",
    "# for i in range(10,110,10):\n",
    "#     model = RandomForestClassifier(n_estimators=i) \n",
    "    \n",
    "#     model.fit(X_train,X_test)\n",
    "    \n",
    "#     predictions = model.predict(y)\n",
    "    \n",
    "#     file = open('SET2/submission'+ str(model) +str(i)+'_updated.csv','a')\n",
    "#     file.write('pet_id,breed_category,pet_category')\n",
    "#     file.write('\\n')\n",
    "#     preds_breed_sgd = list(predictions[:,0])\n",
    "#     preds_pet_sgd = list(predictions[:,1])\n",
    "#     for id,breed,pet in zip(ids,preds_breed_sgd,preds_pet_sgd):\n",
    "#         file.write(str(id)+\",\"+str(int(breed))+\",\"+str(int(pet)))\n",
    "#         file.write('\\n')\n",
    "    \n",
    "#     file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Set 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18834it [00:00, 43017.38it/s]\n",
      "8072it [00:00, 45721.03it/s]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "\n",
    "def cleanDate(issue_date,listing_date):\n",
    "    \n",
    "    format = '%Y-%m-%d %H:%M:%S'\n",
    "    issue_date = datetime.strptime(issue_date,format)\n",
    "    listing_date = datetime.strptime(listing_date,format)\n",
    "    \n",
    "    date = str(listing_date - issue_date).replace('days','')\n",
    "    date = date.replace(' ','')\n",
    "    date = date.split(',')\n",
    "    time = date[1].split(\":\")\n",
    "    hrs = float(date[0])*24 + float(time[0]) + float(time[1])/24 + float(time[2])/(24*60)\n",
    "    \n",
    "    return hrs\n",
    "\n",
    "\n",
    "train_data = pd.read_csv('Dataset-2/train.csv')\n",
    "test_data = pd.read_csv('Dataset-2/test.csv')\n",
    "\n",
    "test_data['condition'].fillna(3,inplace = True)\n",
    "train_data['condition'].fillna(3,inplace = True)\n",
    "\n",
    "ids = test_data['pet_id']\n",
    "s = pd.get_dummies(train_data['color_type'])\n",
    "p = pd.get_dummies(test_data['color_type'])\n",
    "X = pd.concat([train_data,s],axis=1)\n",
    "y = pd.concat([test_data,p],axis = 1)\n",
    "\n",
    "X = X.drop('color_type',axis=1)\n",
    "y = y.drop('color_type',axis=1)\n",
    "\n",
    "X_train = X.drop(['breed_category','pet_category','pet_id'],axis = 1)\n",
    "\n",
    "date_diff = []\n",
    "listing_date = list(X_train['listing_date'])\n",
    "issue_date = list(X_train['issue_date'])\n",
    "\n",
    "for i,j in tqdm(zip(issue_date,listing_date)):\n",
    "    diff = cleanDate(i,j)\n",
    "    date_diff.append(diff)\n",
    "\n",
    "X_train['date_diff (hrs)'] = pd.Series(date_diff)\n",
    "X_train = X_train.drop('issue_date',axis=1)\n",
    "X_train = X_train.drop('listing_date',axis=1)\n",
    "\n",
    "date_diff1 = []\n",
    "listing_date1 = list(y['listing_date'])\n",
    "issue_date1 = list(y['issue_date'])\n",
    "\n",
    "for i,j in tqdm(zip(issue_date1,listing_date1)):\n",
    "    diff = cleanDate(i,j)\n",
    "    date_diff1.append(diff)\n",
    "\n",
    "y['date_diff (hrs)'] = pd.Series(date_diff1)\n",
    "y = y.drop('issue_date',axis=1)\n",
    "y = y.drop('listing_date',axis=1)\n",
    "y = y.drop('pet_id',axis=1)\n",
    "\n",
    "y['date_diff (hrs)'] = y['date_diff (hrs)'].round(2)\n",
    "X_train['date_diff (hrs)'] = X_train['date_diff (hrs)'].round(2)\n",
    "\n",
    "X_test = X[['breed_category','pet_category']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "y['Black Tiger'] =0\n",
    "y['Brown Tiger'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y[X_train.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       105712.46\n",
       "1         4194.00\n",
       "2        47994.12\n",
       "3        27560.04\n",
       "4        11126.75\n",
       "          ...    \n",
       "8067      9472.33\n",
       "8068     19152.00\n",
       "8069      9449.79\n",
       "8070      9306.79\n",
       "8071      9425.96\n",
       "Name: date_diff (hrs), Length: 8072, dtype: float64"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y['date_diff (hrs)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         1769.04\n",
       "1        44706.96\n",
       "2        18057.00\n",
       "3        18139.25\n",
       "4         1258.58\n",
       "           ...   \n",
       "18829     9784.46\n",
       "18830     9273.54\n",
       "18831    70911.12\n",
       "18832     6542.21\n",
       "18833    60230.75\n",
       "Name: date_diff (hrs), Length: 18834, dtype: float64"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train['date_diff (hrs)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:07,  7.77s/it]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import svm, tree\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "\n",
    "\n",
    "# classifiers = []\n",
    "\n",
    "# model2 = tree.DecisionTreeClassifier()\n",
    "# classifiers.append(model2)\n",
    "\n",
    "# model3 = RandomForestClassifier()\n",
    "# classifiers.append(model3)\n",
    "\n",
    "classifiers_breed = []\n",
    "classifiers_pet = []\n",
    "# gnb11 =[]\n",
    "# gnb22 =[]\n",
    "\n",
    "# model2_breed = svm.SVC()\n",
    "# model2_pet = svm.SVC()\n",
    "# classifiers_breed.append(model2_breed)\n",
    "# classifiers_pet.append(model2_pet)\n",
    "\n",
    "# model1_breed = LogisticRegression()\n",
    "# model1_pet = LogisticRegression()\n",
    "# classifiers_breed.append(model1_breed)\n",
    "# classifiers_pet.append(model1_pet)\n",
    "\n",
    "# gnb1 = GaussianNB()\n",
    "# gnb2 = GaussianNB()\n",
    "# classifiers_breed.append(gnb1)\n",
    "# classifiers_pet.append(gnb2)\n",
    "\n",
    "# model1 = XGBClassifier()\n",
    "# model2 = XGBClassifier()\n",
    "# classifiers_breed.append(model1)\n",
    "# classifiers_pet.append(model2)\n",
    "\n",
    "clf1 = MLPClassifier()\n",
    "clf2 = MLPClassifier()\n",
    "classifiers_breed.append(clf1)\n",
    "classifiers_pet.append(clf2)\n",
    "\n",
    "# for clf in classifiers:\n",
    "#     clf.fit(X_train,X_test)\n",
    "    \n",
    "#     predictions = clf.predict(y)\n",
    "    \n",
    "#     file = open('SET2/submission'+ str(clf) +'_updated.csv','a')\n",
    "#     file.write('pet_id,breed_category,pet_category')\n",
    "#     file.write('\\n')\n",
    "#     preds_breed_sgd = list(predictions[:,0])\n",
    "#     preds_pet_sgd = list(predictions[:,1])\n",
    "#     for id,breed,pet in zip(ids,preds_breed_sgd,preds_pet_sgd):\n",
    "#         file.write(str(id)+\",\"+str(int(breed))+\",\"+str(int(pet)))\n",
    "#         file.write('\\n')\n",
    "    \n",
    "#     file.close()\n",
    "    \n",
    "for clf_breed,clf_pet in tqdm(zip(classifiers_breed,classifiers_pet)):\n",
    "    clf_breed.fit(X_train,X_test.iloc[:,0])\n",
    "    clf_pet.fit(X_train,X_test.iloc[:,1])\n",
    "    \n",
    "    y_pred_breed = clf_breed.predict(y)\n",
    "    y_pred_pet = clf_pet.predict(y)\n",
    "    \n",
    "    file = open('SET3/submission'+ str(clf_breed)[:10] +'_updated.csv','a')\n",
    "    file.write('pet_id,breed_category,pet_category')\n",
    "    file.write('\\n')\n",
    "    for id,breed,pet in zip(ids,y_pred_breed,y_pred_pet):\n",
    "        file.write(str(id)+\",\"+str(int(breed))+\",\"+str(int(pet)))\n",
    "        file.write('\\n')\n",
    "    \n",
    "\n",
    "    file.close() \n",
    "\n",
    "# for i in range(10,110,10):\n",
    "#     model = RandomForestClassifier(n_estimators=i) \n",
    "    \n",
    "#     model.fit(X_train,X_test)\n",
    "    \n",
    "#     predictions = model.predict(y)\n",
    "    \n",
    "#     file = open('SET2/submission'+ str(model) +str(i)+'_updated.csv','a')\n",
    "#     file.write('pet_id,breed_category,pet_category')\n",
    "#     file.write('\\n')\n",
    "#     preds_breed_sgd = list(predictions[:,0])\n",
    "#     preds_pet_sgd = list(predictions[:,1])\n",
    "#     for id,breed,pet in zip(ids,preds_breed_sgd,preds_pet_sgd):\n",
    "#         file.write(str(id)+\",\"+str(int(breed))+\",\"+str(int(pet)))\n",
    "#         file.write('\\n')\n",
    "    \n",
    "#     file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Set4 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18834it [00:00, 41008.20it/s]\n",
      "8072it [00:00, 40667.45it/s]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "\n",
    "def cleanDate(issue_date,listing_date):\n",
    "    \n",
    "    format = '%Y-%m-%d %H:%M:%S'\n",
    "    issue_date = datetime.strptime(issue_date,format)\n",
    "    listing_date = datetime.strptime(listing_date,format)\n",
    "    \n",
    "    date = str(listing_date - issue_date).replace('days','')\n",
    "    date = date.replace(' ','')\n",
    "    date = date.split(',')\n",
    "    time = date[1].split(\":\")\n",
    "    hrs = float(date[0])*24 + float(time[0]) + float(time[1])/24 + float(time[2])/(24*60)\n",
    "    \n",
    "    return hrs\n",
    "\n",
    "\n",
    "train_data = pd.read_csv('Dataset-2/train.csv')\n",
    "test_data = pd.read_csv('Dataset-2/test.csv')\n",
    "\n",
    "test_data['condition'].fillna(0,inplace = True)\n",
    "train_data['condition'].fillna(0,inplace = True)\n",
    "\n",
    "ids = test_data['pet_id']\n",
    "s = pd.get_dummies(train_data['color_type'])\n",
    "p = pd.get_dummies(test_data['color_type'])\n",
    "X = pd.concat([train_data,s],axis=1)\n",
    "y = pd.concat([test_data,p],axis = 1)\n",
    "\n",
    "X = X.drop('color_type',axis=1)\n",
    "y = y.drop('color_type',axis=1)\n",
    "\n",
    "X_train = X.drop(['breed_category','pet_category','pet_id'],axis = 1)\n",
    "\n",
    "date_diff = []\n",
    "listing_date = list(X_train['listing_date'])\n",
    "issue_date = list(X_train['issue_date'])\n",
    "\n",
    "for i,j in tqdm(zip(issue_date,listing_date)):\n",
    "    diff = cleanDate(i,j)\n",
    "    date_diff.append(diff)\n",
    "\n",
    "X_train['date_diff (hrs)'] = pd.Series(date_diff)\n",
    "X_train = X_train.drop('issue_date',axis=1)\n",
    "X_train = X_train.drop('listing_date',axis=1)\n",
    "\n",
    "date_diff1 = []\n",
    "listing_date1 = list(y['listing_date'])\n",
    "issue_date1 = list(y['issue_date'])\n",
    "\n",
    "for i,j in tqdm(zip(issue_date1,listing_date1)):\n",
    "    diff = cleanDate(i,j)\n",
    "    date_diff1.append(diff)\n",
    "\n",
    "y['date_diff (hrs)'] = pd.Series(date_diff1)\n",
    "y = y.drop('issue_date',axis=1)\n",
    "y = y.drop('listing_date',axis=1)\n",
    "y = y.drop('pet_id',axis=1)\n",
    "\n",
    "y['date_diff (hrs)'] = y['date_diff (hrs)'].round(2)\n",
    "X_train['date_diff (hrs)'] = X_train['date_diff (hrs)'].round(2)\n",
    "\n",
    "X_test = X[['breed_category','pet_category']]\n",
    "\n",
    "X_train = X_train.drop('date_diff (hrs)',axis =1)\n",
    "# y = y.drop(['Brown Tiger', 'Black Tiger'],axis =1)\n",
    "X_train = X_train.drop(['Brown Tiger', 'Black Tiger'],axis =1)\n",
    "y = y.drop('date_diff (hrs)',axis =1)\n",
    "\n",
    "y = y[X_train.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:31, 31.62s/it]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import svm, tree\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "\n",
    "\n",
    "# classifiers = []\n",
    "\n",
    "# model2 = tree.DecisionTreeClassifier()\n",
    "# classifiers.append(model2)\n",
    "\n",
    "# model3 = RandomForestClassifier()\n",
    "# classifiers.append(model3)\n",
    "\n",
    "classifiers_breed = []\n",
    "classifiers_pet = []\n",
    "# gnb11 =[]\n",
    "# gnb22 =[]\n",
    "\n",
    "# model2_breed = svm.SVC()\n",
    "# model2_pet = svm.SVC()\n",
    "# classifiers_breed.append(model2_breed)\n",
    "# classifiers_pet.append(model2_pet)\n",
    "\n",
    "# model1_breed = LogisticRegression()\n",
    "# model1_pet = LogisticRegression()\n",
    "# classifiers_breed.append(model1_breed)\n",
    "# classifiers_pet.append(model1_pet)\n",
    "\n",
    "# gnb1 = GaussianNB()\n",
    "# gnb2 = GaussianNB()\n",
    "# classifiers_breed.append(gnb1)\n",
    "# classifiers_pet.append(gnb2)\n",
    "\n",
    "# model1 = XGBClassifier()\n",
    "# model2 = XGBClassifier()\n",
    "# classifiers_breed.append(model1)\n",
    "# classifiers_pet.append(model2)\n",
    "\n",
    "clf1 = MLPClassifier()\n",
    "clf2 = MLPClassifier()\n",
    "classifiers_breed.append(clf1)\n",
    "classifiers_pet.append(clf2)\n",
    "\n",
    "# for clf in classifiers:\n",
    "#     clf.fit(X_train,X_test)\n",
    "    \n",
    "#     predictions = clf.predict(y)\n",
    "    \n",
    "#     file = open('SET2/submission'+ str(clf) +'_updated.csv','a')\n",
    "#     file.write('pet_id,breed_category,pet_category')\n",
    "#     file.write('\\n')\n",
    "#     preds_breed_sgd = list(predictions[:,0])\n",
    "#     preds_pet_sgd = list(predictions[:,1])\n",
    "#     for id,breed,pet in zip(ids,preds_breed_sgd,preds_pet_sgd):\n",
    "#         file.write(str(id)+\",\"+str(int(breed))+\",\"+str(int(pet)))\n",
    "#         file.write('\\n')\n",
    "    \n",
    "#     file.close()\n",
    "    \n",
    "for clf_breed,clf_pet in tqdm(zip(classifiers_breed,classifiers_pet)):\n",
    "    clf_breed.fit(X_train,X_test.iloc[:,0])\n",
    "    clf_pet.fit(X_train,X_test.iloc[:,1])\n",
    "    \n",
    "    y_pred_breed = clf_breed.predict(y)\n",
    "    y_pred_pet = clf_pet.predict(y)\n",
    "    \n",
    "    file = open('SET4/submission'+ str(clf_breed)[:10] +'_updated.csv','a')\n",
    "    file.write('pet_id,breed_category,pet_category')\n",
    "    file.write('\\n')\n",
    "    for id,breed,pet in zip(ids,y_pred_breed,y_pred_pet):\n",
    "        file.write(str(id)+\",\"+str(int(breed))+\",\"+str(int(pet)))\n",
    "        file.write('\\n')\n",
    "    \n",
    "\n",
    "    file.close() \n",
    "\n",
    "# for i in range(10,110,10):\n",
    "#     model = RandomForestClassifier(n_estimators=i) \n",
    "    \n",
    "#     model.fit(X_train,X_test)\n",
    "    \n",
    "#     predictions = model.predict(y)\n",
    "    \n",
    "#     file = open('SET2/submission'+ str(model) +str(i)+'_updated.csv','a')\n",
    "#     file.write('pet_id,breed_category,pet_category')\n",
    "#     file.write('\\n')\n",
    "#     preds_breed_sgd = list(predictions[:,0])\n",
    "#     preds_pet_sgd = list(predictions[:,1])\n",
    "#     for id,breed,pet in zip(ids,preds_breed_sgd,preds_pet_sgd):\n",
    "#         file.write(str(id)+\",\"+str(int(breed))+\",\"+str(int(pet)))\n",
    "#         file.write('\\n')\n",
    "    \n",
    "#     file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training set 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18834it [00:00, 36846.11it/s]\n",
      "8072it [00:00, 36789.90it/s]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "\n",
    "def cleanDate(issue_date,listing_date):\n",
    "    \n",
    "    format = '%Y-%m-%d %H:%M:%S'\n",
    "    issue_date = datetime.strptime(issue_date,format)\n",
    "    listing_date = datetime.strptime(listing_date,format)\n",
    "    \n",
    "    date = str(listing_date - issue_date).replace('days','')\n",
    "    date = date.replace(' ','')\n",
    "    date = date.split(',')\n",
    "    time = date[1].split(\":\")\n",
    "    hrs = float(date[0])*24 + float(time[0]) + float(time[1])/24 + float(time[2])/(24*60)\n",
    "    \n",
    "    return hrs\n",
    "\n",
    "\n",
    "train_data = pd.read_csv('Dataset-2/train.csv')\n",
    "test_data = pd.read_csv('Dataset-2/test.csv')\n",
    "\n",
    "test_data['condition'].fillna(1,inplace = True)\n",
    "train_data['condition'].fillna(1,inplace = True)\n",
    "\n",
    "ids = test_data['pet_id']\n",
    "s = pd.get_dummies(train_data['color_type'])\n",
    "p = pd.get_dummies(test_data['color_type'])\n",
    "X = pd.concat([train_data,s],axis=1)\n",
    "y = pd.concat([test_data,p],axis = 1)\n",
    "\n",
    "X = X.drop('color_type',axis=1)\n",
    "y = y.drop('color_type',axis=1)\n",
    "\n",
    "X_train = X.drop(['breed_category','pet_category','pet_id'],axis = 1)\n",
    "\n",
    "date_diff = []\n",
    "listing_date = list(X_train['listing_date'])\n",
    "issue_date = list(X_train['issue_date'])\n",
    "\n",
    "for i,j in tqdm(zip(issue_date,listing_date)):\n",
    "    diff = cleanDate(i,j)\n",
    "    date_diff.append(diff)\n",
    "\n",
    "X_train['date_diff (hrs)'] = pd.Series(date_diff)\n",
    "X_train = X_train.drop('issue_date',axis=1)\n",
    "X_train = X_train.drop('listing_date',axis=1)\n",
    "\n",
    "date_diff1 = []\n",
    "listing_date1 = list(y['listing_date'])\n",
    "issue_date1 = list(y['issue_date'])\n",
    "\n",
    "for i,j in tqdm(zip(issue_date1,listing_date1)):\n",
    "    diff = cleanDate(i,j)\n",
    "    date_diff1.append(diff)\n",
    "\n",
    "y['date_diff (hrs)'] = pd.Series(date_diff1)\n",
    "y = y.drop('issue_date',axis=1)\n",
    "y = y.drop('listing_date',axis=1)\n",
    "y = y.drop('pet_id',axis=1)\n",
    "\n",
    "y['date_diff (hrs)'] = y['date_diff (hrs)'].round(2)\n",
    "X_train['date_diff (hrs)'] = X_train['date_diff (hrs)'].round(2)\n",
    "\n",
    "X_test = X[['breed_category','pet_category']]\n",
    "\n",
    "X_train = X_train.drop('date_diff (hrs)',axis =1)\n",
    "# y = y.drop(['Brown Tiger', 'Black Tiger'],axis =1)\n",
    "X_train = X_train.drop(['Brown Tiger', 'Black Tiger'],axis =1)\n",
    "y = y.drop('date_diff (hrs)',axis =1)\n",
    "\n",
    "y = y[X_train.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:29, 29.69s/it]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import svm, tree\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "\n",
    "\n",
    "# classifiers = []\n",
    "\n",
    "# model2 = tree.DecisionTreeClassifier()\n",
    "# classifiers.append(model2)\n",
    "\n",
    "# model3 = RandomForestClassifier()\n",
    "# classifiers.append(model3)\n",
    "\n",
    "classifiers_breed = []\n",
    "classifiers_pet = []\n",
    "# gnb11 =[]\n",
    "# gnb22 =[]\n",
    "\n",
    "# model2_breed = svm.SVC()\n",
    "# model2_pet = svm.SVC()\n",
    "# classifiers_breed.append(model2_breed)\n",
    "# classifiers_pet.append(model2_pet)\n",
    "\n",
    "# model1_breed = LogisticRegression()\n",
    "# model1_pet = LogisticRegression()\n",
    "# classifiers_breed.append(model1_breed)\n",
    "# classifiers_pet.append(model1_pet)\n",
    "\n",
    "# gnb1 = GaussianNB()\n",
    "# gnb2 = GaussianNB()\n",
    "# classifiers_breed.append(gnb1)\n",
    "# classifiers_pet.append(gnb2)\n",
    "\n",
    "# model1 = XGBClassifier()\n",
    "# model2 = XGBClassifier()\n",
    "# classifiers_breed.append(model1)\n",
    "# classifiers_pet.append(model2)\n",
    "\n",
    "clf1 = MLPClassifier()\n",
    "clf2 = MLPClassifier()\n",
    "classifiers_breed.append(clf1)\n",
    "classifiers_pet.append(clf2)\n",
    "\n",
    "# for clf in classifiers:\n",
    "#     clf.fit(X_train,X_test)\n",
    "    \n",
    "#     predictions = clf.predict(y)\n",
    "    \n",
    "#     file = open('SET2/submission'+ str(clf) +'_updated.csv','a')\n",
    "#     file.write('pet_id,breed_category,pet_category')\n",
    "#     file.write('\\n')\n",
    "#     preds_breed_sgd = list(predictions[:,0])\n",
    "#     preds_pet_sgd = list(predictions[:,1])\n",
    "#     for id,breed,pet in zip(ids,preds_breed_sgd,preds_pet_sgd):\n",
    "#         file.write(str(id)+\",\"+str(int(breed))+\",\"+str(int(pet)))\n",
    "#         file.write('\\n')\n",
    "    \n",
    "#     file.close()\n",
    "    \n",
    "for clf_breed,clf_pet in tqdm(zip(classifiers_breed,classifiers_pet)):\n",
    "    clf_breed.fit(X_train,X_test.iloc[:,0])\n",
    "    clf_pet.fit(X_train,X_test.iloc[:,1])\n",
    "    \n",
    "    y_pred_breed = clf_breed.predict(y)\n",
    "    y_pred_pet = clf_pet.predict(y)\n",
    "    \n",
    "    file = open('SET5/submission'+ str(clf_breed)[:10] +'_updated.csv','a')\n",
    "    file.write('pet_id,breed_category,pet_category')\n",
    "    file.write('\\n')\n",
    "    for id,breed,pet in zip(ids,y_pred_breed,y_pred_pet):\n",
    "        file.write(str(id)+\",\"+str(int(breed))+\",\"+str(int(pet)))\n",
    "        file.write('\\n')\n",
    "    \n",
    "\n",
    "    file.close() \n",
    "\n",
    "# for i in range(10,110,10):\n",
    "#     model = RandomForestClassifier(n_estimators=i) \n",
    "    \n",
    "#     model.fit(X_train,X_test)\n",
    "    \n",
    "#     predictions = model.predict(y)\n",
    "    \n",
    "#     file = open('SET2/submission'+ str(model) +str(i)+'_updated.csv','a')\n",
    "#     file.write('pet_id,breed_category,pet_category')\n",
    "#     file.write('\\n')\n",
    "#     preds_breed_sgd = list(predictions[:,0])\n",
    "#     preds_pet_sgd = list(predictions[:,1])\n",
    "#     for id,breed,pet in zip(ids,preds_breed_sgd,preds_pet_sgd):\n",
    "#         file.write(str(id)+\",\"+str(int(breed))+\",\"+str(int(pet)))\n",
    "#         file.write('\\n')\n",
    "    \n",
    "#     file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Set 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18834it [00:00, 39601.68it/s]\n",
      "8072it [00:00, 47131.08it/s]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "\n",
    "def cleanDate(issue_date,listing_date):\n",
    "    \n",
    "    format = '%Y-%m-%d %H:%M:%S'\n",
    "    issue_date = datetime.strptime(issue_date,format)\n",
    "    listing_date = datetime.strptime(listing_date,format)\n",
    "    \n",
    "    date = str(listing_date - issue_date).replace('days','')\n",
    "    date = date.replace(' ','')\n",
    "    date = date.split(',')\n",
    "    time = date[1].split(\":\")\n",
    "    hrs = float(date[0])*24 + float(time[0]) + float(time[1])/24 + float(time[2])/(24*60)\n",
    "    \n",
    "    return hrs\n",
    "\n",
    "\n",
    "train_data = pd.read_csv('Dataset-2/train.csv')\n",
    "test_data = pd.read_csv('Dataset-2/test.csv')\n",
    "\n",
    "test_data['condition'].fillna(3,inplace = True)\n",
    "train_data['condition'].fillna(3,inplace = True)\n",
    "\n",
    "ids = test_data['pet_id']\n",
    "s = pd.get_dummies(train_data['color_type'])\n",
    "p = pd.get_dummies(test_data['color_type'])\n",
    "X = pd.concat([train_data,s],axis=1)\n",
    "y = pd.concat([test_data,p],axis = 1)\n",
    "\n",
    "X = X.drop('color_type',axis=1)\n",
    "y = y.drop('color_type',axis=1)\n",
    "\n",
    "X_train = X.drop(['breed_category','pet_category','pet_id'],axis = 1)\n",
    "\n",
    "date_diff = []\n",
    "listing_date = list(X_train['listing_date'])\n",
    "issue_date = list(X_train['issue_date'])\n",
    "\n",
    "for i,j in tqdm(zip(issue_date,listing_date)):\n",
    "    diff = cleanDate(i,j)\n",
    "    date_diff.append(diff)\n",
    "\n",
    "X_train['date_diff (hrs)'] = pd.Series(date_diff)\n",
    "X_train = X_train.drop('issue_date',axis=1)\n",
    "X_train = X_train.drop('listing_date',axis=1)\n",
    "\n",
    "date_diff1 = []\n",
    "listing_date1 = list(y['listing_date'])\n",
    "issue_date1 = list(y['issue_date'])\n",
    "\n",
    "for i,j in tqdm(zip(issue_date1,listing_date1)):\n",
    "    diff = cleanDate(i,j)\n",
    "    date_diff1.append(diff)\n",
    "\n",
    "y['date_diff (hrs)'] = pd.Series(date_diff1)\n",
    "y = y.drop('issue_date',axis=1)\n",
    "y = y.drop('listing_date',axis=1)\n",
    "y = y.drop('pet_id',axis=1)\n",
    "\n",
    "y['date_diff (hrs)'] = y['date_diff (hrs)'].round(2)\n",
    "X_train['date_diff (hrs)'] = X_train['date_diff (hrs)'].round(2)\n",
    "\n",
    "X_test = X[['breed_category','pet_category']]\n",
    "\n",
    "X_train = X_train.drop('date_diff (hrs)',axis =1)\n",
    "# y = y.drop(['Brown Tiger', 'Black Tiger'],axis =1)\n",
    "X_train = X_train.drop(['Brown Tiger', 'Black Tiger'],axis =1)\n",
    "y = y.drop('date_diff (hrs)',axis =1)\n",
    "\n",
    "y = y[X_train.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:16, 16.74s/it]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import svm, tree\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "\n",
    "\n",
    "# classifiers = []\n",
    "\n",
    "# model2 = tree.DecisionTreeClassifier()\n",
    "# classifiers.append(model2)\n",
    "\n",
    "# model3 = RandomForestClassifier()\n",
    "# classifiers.append(model3)\n",
    "\n",
    "classifiers_breed = []\n",
    "classifiers_pet = []\n",
    "# gnb11 =[]\n",
    "# gnb22 =[]\n",
    "\n",
    "# model2_breed = svm.SVC()\n",
    "# model2_pet = svm.SVC()\n",
    "# classifiers_breed.append(model2_breed)\n",
    "# classifiers_pet.append(model2_pet)\n",
    "\n",
    "# model1_breed = LogisticRegression()\n",
    "# model1_pet = LogisticRegression()\n",
    "# classifiers_breed.append(model1_breed)\n",
    "# classifiers_pet.append(model1_pet)\n",
    "\n",
    "# gnb1 = GaussianNB()\n",
    "# gnb2 = GaussianNB()\n",
    "# classifiers_breed.append(gnb1)\n",
    "# classifiers_pet.append(gnb2)\n",
    "\n",
    "# model1 = XGBClassifier()\n",
    "# model2 = XGBClassifier()\n",
    "# classifiers_breed.append(model1)\n",
    "# classifiers_pet.append(model2)\n",
    "\n",
    "clf1 = MLPClassifier()\n",
    "clf2 = MLPClassifier()\n",
    "classifiers_breed.append(clf1)\n",
    "classifiers_pet.append(clf2)\n",
    "\n",
    "# for clf in classifiers:\n",
    "#     clf.fit(X_train,X_test)\n",
    "    \n",
    "#     predictions = clf.predict(y)\n",
    "    \n",
    "#     file = open('SET2/submission'+ str(clf) +'_updated.csv','a')\n",
    "#     file.write('pet_id,breed_category,pet_category')\n",
    "#     file.write('\\n')\n",
    "#     preds_breed_sgd = list(predictions[:,0])\n",
    "#     preds_pet_sgd = list(predictions[:,1])\n",
    "#     for id,breed,pet in zip(ids,preds_breed_sgd,preds_pet_sgd):\n",
    "#         file.write(str(id)+\",\"+str(int(breed))+\",\"+str(int(pet)))\n",
    "#         file.write('\\n')\n",
    "    \n",
    "#     file.close()\n",
    "    \n",
    "for clf_breed,clf_pet in tqdm(zip(classifiers_breed,classifiers_pet)):\n",
    "    clf_breed.fit(X_train,X_test.iloc[:,0])\n",
    "    clf_pet.fit(X_train,X_test.iloc[:,1])\n",
    "    \n",
    "    y_pred_breed = clf_breed.predict(y)\n",
    "    y_pred_pet = clf_pet.predict(y)\n",
    "    \n",
    "    file = open('SET6/submission'+ str(clf_breed)[:10] +'_updated.csv','a')\n",
    "    file.write('pet_id,breed_category,pet_category')\n",
    "    file.write('\\n')\n",
    "    for id,breed,pet in zip(ids,y_pred_breed,y_pred_pet):\n",
    "        file.write(str(id)+\",\"+str(int(breed))+\",\"+str(int(pet)))\n",
    "        file.write('\\n')\n",
    "    \n",
    "\n",
    "    file.close() \n",
    "\n",
    "# for i in range(10,110,10):\n",
    "#     model = RandomForestClassifier(n_estimators=i) \n",
    "    \n",
    "#     model.fit(X_train,X_test)\n",
    "    \n",
    "#     predictions = model.predict(y)\n",
    "    \n",
    "#     file = open('SET2/submission'+ str(model) +str(i)+'_updated.csv','a')\n",
    "#     file.write('pet_id,breed_category,pet_category')\n",
    "#     file.write('\\n')\n",
    "#     preds_breed_sgd = list(predictions[:,0])\n",
    "#     preds_pet_sgd = list(predictions[:,1])\n",
    "#     for id,breed,pet in zip(ids,preds_breed_sgd,preds_pet_sgd):\n",
    "#         file.write(str(id)+\",\"+str(int(breed))+\",\"+str(int(pet)))\n",
    "#         file.write('\\n')\n",
    "    \n",
    "#     file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
